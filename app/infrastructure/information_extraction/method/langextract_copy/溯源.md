实体溯源功能代码分析
1. 整体概述
在LangExtract库的resolver模块中，align_extractions和_fuzzy_align_extraction两个函数共同实现了实体溯源功能。实体溯源是指将从文本中提取的实体与其在原始文档中的确切位置进行关联的过程，这使得我们不仅能知道提取了什么实体，还能知道它在原文档中的具体位置。
2. 代码实现逻辑
2.1 _fuzzy_align_extraction函数 (L696-L816)
这个函数实现了模糊匹配算法，用于将提取的实体定位到源文本中的确切位置：
```python
def _fuzzy_align_extraction(
      self,
      extraction: data.Extraction,
      source_tokens: list[str],
      tokenized_text: tokenizer.TokenizedText,
      token_offset: int,
      char_offset: int,
      fuzzy_alignment_threshold: float = _FUZZY_ALIGNMENT_MIN_THRESHOLD,
  ) -> data.Extraction | None:
```
主要处理步骤：
预处理阶段：
将提取的实体文本分解为小写形式的tokens (_tokenize_with_lowercase)
对tokens进行轻量级词干化处理 (_normalize_token)，以处理单复数等变化
相似度匹配算法：
使用滑动窗口技术遍历源文本的所有可能窗口
使用difflib.SequenceMatcher计算匹配比率
采用计数交集优化作为快速筛选条件，减少不必要的昂贵匹配操作
最佳匹配查找：
扫描所有候选窗口，找出具有最高匹配比率的窗口
只有当匹配比率达到阈值(fuzzy_alignment_threshold)时才接受匹配
位置信息设置：
成功匹配后，设置提取实体的token区间和字符区间
设置对齐状态为MATCH_FUZZY
2.2 align_extractions函数 (L818-L1006)
这个函数是实体溯源的主要协调者，负责整体的对齐流程：
```python
def align_extractions(
      self,
      extraction_groups: Sequence[Sequence[data.Extraction]],
      source_text: str,
      token_offset: int = 0,
      char_offset: int = 0,
      delim: str = "\u241F",  # Unicode Symbol for unit separator
      enable_fuzzy_alignment: bool = True,
      fuzzy_alignment_threshold: float = _FUZZY_ALIGNMENT_MIN_THRESHOLD,
      accept_match_lesser: bool = True,
  ) -> Sequence[Sequence[data.Extraction]]:
```
处理流程：
初始化阶段：
对源文本进行tokenization
构建提取实体的token序列，用分隔符连接
精确匹配阶段：
使用difflib的匹配块算法进行精确匹配
设置匹配成功的实体的token区间和字符区间
分类为完全匹配(MATCH_EXACT)或部分匹配(MATCH_LESSER)
模糊匹配阶段：
对未能精确匹配的实体应用模糊匹配算法
调用_fuzzy_align_extraction函数
结果整理：
将所有对齐结果按原始组别重新组织
3. 实体溯源算法原理
实体溯源算法采用了两阶段匹配策略：
精确匹配阶段：首先尝试精确匹配，使用difflib.SequenceMatcher找到完全一致的文本片段
模糊匹配阶段：对于精确匹配失败的实体，使用滑动窗口算法寻找最相似的文本片段
这种设计提高了实体溯源的准确性和鲁棒性，即使提取的实体与原文本存在细微差异（如大小写、单复数、标点符号等），也能正确关联到原始位置。
4. 关键特性
容错性：通过模糊匹配算法处理文本变体
高效性：使用计数交集优化减少不必要的计算
准确性：同时提供token级别和字符级别的位置信息
灵活性：可配置匹配阈值和是否启用模糊匹配
这种实体溯源机制对于构建高质量的知识图谱至关重要，因为它不仅提取了实体，还保留了其在源文档中的精确位置信息，便于后续验证和引用。