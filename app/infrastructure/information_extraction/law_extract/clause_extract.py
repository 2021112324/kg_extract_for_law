import asyncio
import json
import logging
import os
import re

from app.infrastructure.information_extraction.base import Entity, Relationship
from app.infrastructure.information_extraction.factory import InformationExtractionFactory
from app.infrastructure.information_extraction.law_extract.prompt.example import example_for_clause, \
    example_for_file_info
from app.infrastructure.information_extraction.law_extract.prompt.prompt import prompt_for_clause, prompt_for_file_info
from app.infrastructure.information_extraction.law_extract.prompt.schema import schema_for_clause, schema_for_file_info
from app.infrastructure.information_extraction.method.base import LangextractConfig
from app.infrastructure.string_utils.id_tool import generate_hex_uuid
from app.infrastructure.string_utils.str_clean import clean_string_with_only_words, clean_string_for_neo4j_extended, \
    replace_full_corner_space, replace_zero_width_chars

CLAUSE_MADEL = "qwen3-30b-a3b-instruct-2507"
CLAUSE_MADEL_API = "gpustack_342609ce423be29a_4371426b285a91dc44fb4e8d72454847"
CLAUSE_MADEL_KEY = "http://222.171.219.26:20001/v1/chat/completions"

# MAX_CHUNK_SIZE = int(os.getenv("MAX_CHUNK_SIZE", "5000"))
# BATCH_LENGTH = int(os.getenv("BATCH_LENGTH", "5"))
# MAX_WORKERS = int(os.getenv("MAX_WORKERS", "3"))
# TIMEOUT = int(os.getenv("TIMEOUT", "300"))

MAX_CHAR_BUFFER = 7500
BATCH_LENGTH = 5
MAX_WORKERS = 3
TIMEOUT = 3000

class ClauseCache:
    def __init__(self):
        self.file_info = {}
        self.clause_cache = {}


class ClauseExtractor:
    def __init__(self, max_concurrent: int = 50):
        self.extractor_config = LangextractConfig(
            model_name=CLAUSE_MADEL,
            api_key=CLAUSE_MADEL_API,
            api_url=CLAUSE_MADEL_KEY,
            config={
                    "timeout": TIMEOUT
                },
            max_char_buffer=MAX_CHAR_BUFFER,
            batch_length=BATCH_LENGTH,
            max_workers=MAX_WORKERS,
            # resolver_params=
        )
        self.extractor = InformationExtractionFactory.create(
            "langextract",
            max_retries=5,
            config=self.extractor_config
        )
        self.semaphore = asyncio.Semaphore(max_concurrent)  # æ·»åŠ ä¿¡å·é‡

        # å®½æ¾æ¨¡å¼æ ‡å¿—ï¼ˆTrueåˆ™å°†å¤„ç†å¤±è´¥çš„æ¡æ¬¾ç›´æ¥ä½œä¸ºæ³•æ¡å®ä½“æ·»åŠ åˆ°å›¾è°±ä¸­ï¼ˆä¸è€ƒè™‘æ³•æ¡ä¿¡æ¯ã€ï¼‰ï¼‰
        self.lenient_mode = False

    async def extract_clauses(
            self,
            filename: str,
            text: str
    ) -> dict:
        """
        å®ç°åŠŸèƒ½ï¼šä»æ³•è§„æ–‡ä»¶ä¸­æŠ½å–æ¡æ¬¾çŸ¥è¯†å›¾è°±æ•°æ®
        :param filename:
        :param text:
        :return:
        """
        try:
            logging.info("ğŸ“„â³:å¼€å§‹æ¡æ¬¾çŸ¥è¯†å›¾è°±æŠ½å–")
            # åˆ†å‰²æ¡æ¬¾æ•°æ®
            logging.info("ğŸ“„:å¼€å§‹åˆ†å‰²æ¡æ¬¾")
            clauses_data = await self.split_clause(
                text
            )
            logging.info("ğŸ“„:ç»“æŸåˆ†å‰²æ¡æ¬¾")
            # æ£€æŸ¥ç¼“å­˜
            """
            ç¼“å­˜cacheä¸ºClauseCacheå¯¹è±¡ï¼Œå…¶ä¸­çš„cache.clause_cacheè®°å½•ç»“æ„ï¼š
            {
                "ç¬¬Xæ¡" :{}
            }
            éå†ç¼“å­˜ï¼Œé€šè¿‡ clauses["æ¡æ¬¾ç¼–å·"] ç­‰äº ç¼“å­˜çš„"ç¬¬Xæ¡"ï¼Œ
            å°†clausesä¸­å·²ç»å¤„ç†è¿‡çš„æ¡æ¬¾æ•°æ®ä»clausesä¸­åˆ é™¤ï¼Œ
            ç„¶åå¯¹clausesä¸­æœªå¤„ç†è¿‡çš„æ¡æ¬¾æ•°æ®è¿›è¡Œå¤„ç†
            """
            logging.info("ğŸ“„:å¼€å§‹å¤„ç†æ–‡ä»¶ä¿¡æ¯")
            clause_cache = ClauseCache()
            file_info = clauses_data.get("file_info")
            if not file_info:
                logging.error("ğŸ“„âŒï¼šæ–‡ä»¶ä¿¡æ¯ä¸ºç©º")
                raise ValueError("æ–‡ä»¶ä¿¡æ¯ä¸ºç©º")
            file_info_result = await self.kg_extract_from_file_info(
                filename=filename,
                clause_cache=clause_cache,
                file_info=file_info
            )

            logging.info("ğŸ“„:ç»“æŸå¤„ç†æ–‡ä»¶ä¿¡æ¯")

            logging.info("ğŸ“„:å¼€å§‹å¤„ç†æ¡æ¬¾æ•°æ®")
            clauses = clauses_data.get("clauses")
            if not clauses:
                logging.error("ğŸ“„âŒï¼šæ¡æ¬¾æ•°æ®ä¸ºç©º")
                raise ValueError("æ¡æ¬¾æ•°æ®ä¸ºç©º")
            # æ‰¹é‡å¤„ç†æ¡æ¬¾æ•°æ®
            tasks = [
                self.kg_extract_from_clause(
                    filename=filename,
                    clause_cache=clause_cache,
                    one_clause=clause
                )
                for clause in clauses
            ]
            # ä½¿ç”¨ asyncio.gather å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            logging.info("ğŸ“„ğŸŒ:å¼€å§‹æŠ½å–æ¡æ¬¾çŸ¥è¯†å›¾è°±")
            results = await asyncio.gather(*tasks, return_exceptions=True)
            logging.info("ğŸ“„:ç»“æŸæŠ½å–æ¡æ¬¾çŸ¥è¯†å›¾è°±")

            logging.info("ğŸ“„:å¼€å§‹å¤„ç†æ¡æ¬¾æ•°æ®ç»“æœ")
            failed_results = []
            failed_clauses = []
            successful_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logging.error(f"æ¡æ¬¾ {i+1} å¤„ç†å¤±è´¥: {result}")
                    failed_results.append((i+1, result))
                    # å°†å¯¹åº”çš„clauseä¿å­˜è‡³failed_clauses
                    failed_clauses.append(clauses[i])
                else:
                    successful_results.append(result)
            if failed_results:
                logging.error("ğŸ“„ğŸ”¥ï¼šä»¥ä¸‹æ¡æ¬¾å¤„ç†å¤±è´¥")
                logging.info("==============================================================")
                for i, result in failed_results:
                    logging.error(f"æ¡æ¬¾ {i} å¤„ç†å¤±è´¥: {result}")
                logging.info("==============================================================")
            # TODO:DELETEä»¥æ ¼å¼åŒ–jsonè¾“å‡ºæ¯ä¸ªæ¡æ¬¾å¤„ç†ç»“æœ
            print(json.dumps(file_info_result, ensure_ascii=False, indent=4))
            logging.info("==============================================================")
            for i, result in enumerate(successful_results):
                logging.info(f"æ¡æ¬¾ {i+1} å¤„ç†ç»“æœ: ")
                logging.info(json.dumps(result, ensure_ascii=False, indent=4))
            logging.info("==============================================================")

            if not self.lenient_mode and failed_results:
                logging.error("ğŸ“„ğŸ”´ğŸ”´ğŸ”´ï¼šä¸¥è°¨æ¨¡å¼ï¼šå­˜åœ¨å¤„ç†å¤±è´¥çš„æ³•æ¡ï¼Œè¯·æ£€æŸ¥é—®é¢˜ï¼ï¼ï¼")
                raise ValueError("å­˜åœ¨å¤„ç†å¤±è´¥çš„æ³•æ¡ï¼Œè¯·æ£€æŸ¥é—®é¢˜ï¼ï¼ï¼")
            final_kg = await self.process_extracted_data(
                filename=filename,
                extracted_file_info=file_info_result,
                extracted_success_clauses=successful_results,
                extracted_failed_clauses=failed_clauses
            )
            logging.info("ğŸ“„:ç»“æŸå¤„ç†æ¡æ¬¾æ•°æ®")

            return final_kg
        except Exception as e:
            # å¦‚æœç¼“å­˜ä¸­å­˜åœ¨ç»“æœï¼Œå°†ç¼“å­˜ä¿å­˜èµ·æ¥
            logging.error("ğŸ“„âŒï¼šæ¡æ¬¾çŸ¥è¯†å›¾è°±æŠ½å–æŠ¥é”™: %s", e)
            raise e

    async def split_clause(
            self,
            text: str
    ) -> dict:
        """
å®ç°åŠŸèƒ½ï¼šåˆ‡åˆ†æ³•è§„æ–‡ä»¶ï¼Œå°†å…¶æ•´ç†æˆæ³•è§„æ–‡ä»¶åŸºç¡€ä¿¡æ¯ã€æ¡æ¬¾çš„ç»“æ„åŒ–æ•°æ®ï¼Œå¤§è‡´é€»è¾‘å¦‚ä¸‹ï¼š
1. file_infoè®°å½•æ–‡ä»¶å¼€å¤´å†…å®¹ï¼Œcurrent_chapterè®°å½•å½“å‰ç« ï¼Œcurrent_sectionè®°å½•å½“å‰èŠ‚ã€‚
2. è¯»å–æ–‡ä»¶å†…å®¹ï¼Œè‹¥è¯»å–åˆ°ç« å†…å®¹ï¼ˆå³"ç¬¬Xç«  XXX"ï¼‰ï¼Œåˆ™current_chapterè®°å½•å½“å‰ç« å†…å®¹ï¼ˆå³"ç¬¬Xç«  XXX"ï¼‰ï¼›
    è‹¥è¯»å–åˆ°èŠ‚å†…å®¹ï¼ˆå³"ç¬¬XèŠ‚ XXX"ï¼‰ï¼Œåˆ™current_sectionè®°å½•å½“å‰èŠ‚å†…å®¹ï¼ˆå³"ç¬¬XèŠ‚ XXX"ï¼‰ï¼›
    è‹¥è¯»å–åˆ°æ¡æ¬¾å†…å®¹ï¼ˆå³"ç¬¬Xæ¡ XXX"ï¼‰ï¼Œåˆ™å°†current_chapterã€current_sectionã€æ¡æ¬¾å†…å®¹è®°å½•åˆ°ç»“æœä¸­ï¼›
3. file_infoä»å¼€å¤´å¼€å§‹è®°å½•ï¼Œå¦‚æœè¯»å–åˆ°"ç¬¬ä¸€èŠ‚"ï¼Œåˆ™å°†"ç¬¬ä¸€èŠ‚"å‰çš„å†…å®¹è®°å½•åˆ°file_infoä¸­ï¼Œå¹¶åˆ é™¤file_infoæ–‡æœ¬æœ«å°¾çš„ç« å’ŒèŠ‚ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
4. æ¡æ¬¾å†…å®¹ä¸ºä¸Šä¸€ä¸ª"ç¬¬Xæ¡"åˆ°ä¸‹ä¸€ä¸ª"ç¬¬Xæ¡"ä¹‹é—´çš„å†…å®¹ï¼Œæˆ–è€…è¯»åˆ°ç« æˆ–èŠ‚çš„æ ‡å¿—ï¼Œæˆ–è€…è¯»åˆ°æ–‡ä»¶æœ«å°¾ï¼Œæˆ–è€…è¯»åˆ°"é™„å½•"ã€"é™„ä»¶"ç­‰æ¡æ¬¾éƒ¨åˆ†ç»“æŸæ ‡å¿—ã€‚
    åˆ‡åˆ†åçš„æ•°æ®ç»“æ„ï¼š
    {
        "file_info": "æ–‡ä»¶å¼€å¤´å†…å®¹",
        "clauses": [
            {
                "ç« ": "ç« å†…å®¹",
                "èŠ‚": "èŠ‚å†…å®¹",
                "æ¡æ¬¾ç¼–å·": "ç¬¬å‡ æ¡"
                "æ¡æ¬¾å†…å®¹": "æ¡æ¬¾å†…å®¹ï¼Œä¸åŒ…å«å¼€å¤´çš„"ç¬¬å‡ æ¡""
            }
        ]
    }
        :param text:
        :return:
        """
        # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ - åŒ¹é…è¡Œé¦–çš„"ç¬¬Xç« /èŠ‚/æ¡ "æ ¼å¼ï¼ˆä¸­é—´å¯èƒ½æœ‰ç©ºæ ¼ï¼Œä½†åé¢å¿…é¡»æœ‰ç©ºæ ¼ï¼‰
        chapter_pattern = re.compile(r'^ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+\s*ç« \s+.*', re.MULTILINE)
        section_pattern = re.compile(r'^ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+\s*èŠ‚\s+.*', re.MULTILINE)
        clause_pattern = re.compile(r'^ç¬¬([é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+)\s*æ¡\s*(.*)', re.MULTILINE)

        # å®šä¹‰ç»“æŸæ ‡å¿—
        end_markers = ['é™„å½•', 'é™„ä»¶', 'é™„è¡¨', 'åè®°', 'å‚è€ƒæ–‡çŒ®', 'ç´¢å¼•']

        lines = text.split('\n')

        # åˆå§‹åŒ–å˜é‡
        file_info = ""
        current_chapter = ""
        current_section = ""
        clauses = []

        # è®°å½•file_infoçš„ç»“æŸä½ç½®ï¼ˆç¬¬ä¸€ç« æˆ–ç¬¬ä¸€èŠ‚ï¼‰
        file_info_end_idx = None
        clause_start_idx = None
        for i, line in enumerate(lines):
            if not line.strip():
                continue
            # é€è¡Œè¿›è¡ŒåŒ¹é…
            if chapter_pattern.match(line.lstrip(' \t\r\n\f\v#-*â€¢Â·')):
                # è®°å½•å¼€å¤´å†…å®¹çš„ç»“æŸä½ç½®ï¼ˆä¸åŒ…å«è¯¥è¡Œï¼‰
                file_info_end_idx = i
                # å°†ç« å†…å®¹è®°å½•åˆ°current_chapterä¸­
                current_chapter = line.strip().lstrip(' \t\r\n\f\v#-*â€¢Â·')
            if section_pattern.match(line.lstrip(' \t\r\n\f\v#-*â€¢Â·')):
                # å°†èŠ‚å†…å®¹è®°å½•åˆ°current_sectionä¸­
                current_section = line.strip().lstrip(' \t\r\n\f\v#-*â€¢Â·')
            if clause_pattern.match(line.lstrip(' \t\r\n\f\v#-*â€¢Â·')):
                # è®°å½•æ¡æ¬¾å†…å®¹çš„å¼€å§‹ä½ç½®ï¼ˆåŒ…å«è¯¥è¡Œï¼‰
                clause_start_idx = i
                if not file_info_end_idx:
                    file_info_end_idx = i
                break

        if not clause_start_idx:
            logging.error("ğŸ“„âŒï¼šæ–‡æœ¬ä¸­åŒ¹é…æ¡æ¬¾å¤±è´¥")
            raise ValueError("æ–‡æœ¬ä¸­åŒ¹é…æ¡æ¬¾å¤±è´¥")

        try:
            # æå–file_infoï¼šä»å¼€å¤´åˆ°ç¬¬ä¸€èŠ‚ä¹‹å‰çš„å†…å®¹
            file_info = '\n'.join(lines[:file_info_end_idx]).rstrip()
            # æå–ç¬¬ä¸€æ¡çš„æ¡æ¬¾å†…å®¹ï¼Œå¹¶å°†å…¶æ‹¼æ¥è¿›file_infoä¸­

            current_clause_content = ""
            current_clause_number = ""

            # éå†æ¡æ¬¾å†…å®¹
            for i in range(clause_start_idx, len(lines)):
                line = lines[i]
                if not line.strip():
                    continue
                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç»“æŸæ ‡å¿—
                is_end_marker = False
                for marker in end_markers:
                    if line.lstrip().startswith(marker):
                        is_end_marker = True
                        break
                if is_end_marker:
                    # å¦‚æœå½“å‰æ­£åœ¨æ”¶é›†æ¡æ¬¾å†…å®¹ï¼Œåˆ™ä¿å­˜å®ƒ
                    if current_clause_content:
                        clauses.append({
                            "ç« ": clean_string(current_chapter),
                            "èŠ‚": clean_string(current_section),
                            "æ¡æ¬¾ç¼–å·": clean_string(current_clause_number),
                            "æ¡æ¬¾å†…å®¹": clean_string(current_clause_content)
                        })
                        current_clause_content = ""
                        current_clause_number = ""
                    break

                # æ£€æŸ¥æ˜¯å¦æ˜¯ç« ï¼ˆåŒ¹é…è¡Œé¦–ï¼‰
                if chapter_pattern.match(line.lstrip(' \t\r\n\f\v#-*â€¢Â·')):
                    # å¦‚æœå½“å‰æ­£åœ¨æ”¶é›†æ¡æ¬¾å†…å®¹ï¼Œåˆ™å…ˆä¿å­˜å®ƒ
                    if current_clause_content:
                        clauses.append({
                            "ç« ": clean_string(current_chapter),
                            "èŠ‚": clean_string(current_section),
                            "æ¡æ¬¾ç¼–å·": clean_string(current_clause_number),
                            "æ¡æ¬¾å†…å®¹": clean_string(current_clause_content)
                        })
                        current_clause_content = ""
                        current_clause_number = ""

                    # æ›´æ–°å½“å‰ç« 
                    current_chapter = line.strip().lstrip(' \t\r\n\f\v#-*â€¢Â·')
                    # æ¸…ç©ºå½“å‰èŠ‚
                    current_section = ""
                    continue

                # æ£€æŸ¥æ˜¯å¦æ˜¯èŠ‚ï¼ˆåŒ¹é…è¡Œé¦–ï¼‰
                if section_pattern.match(line.lstrip(' \t\r\n\f\v#-*â€¢Â·')):
                    # å¦‚æœå½“å‰æ­£åœ¨æ”¶é›†æ¡æ¬¾å†…å®¹ï¼Œåˆ™å…ˆä¿å­˜å®ƒ
                    if current_clause_content:
                        clauses.append({
                            "ç« ": clean_string(current_chapter),
                            "èŠ‚": clean_string(current_section),
                            "æ¡æ¬¾ç¼–å·": clean_string(current_clause_number),
                            "æ¡æ¬¾å†…å®¹": clean_string(current_clause_content)
                        })
                        current_clause_content = ""
                        current_clause_number = ""

                    # æ›´æ–°å½“å‰èŠ‚
                    current_section = line.strip().lstrip(' \t\r\n\f\v#-*â€¢Â·')
                    continue

                # æ£€æŸ¥æ˜¯å¦æ˜¯æ¡æ¬¾ï¼ˆåŒ¹é…è¡Œé¦–ï¼‰
                if clause_pattern.match(line.lstrip(' \t\r\n\f\v#-*â€¢Â·')):
                    # å¦‚æœå½“å‰æ­£åœ¨æ”¶é›†æ¡æ¬¾å†…å®¹ï¼Œåˆ™å…ˆä¿å­˜ä¹‹å‰çš„æ¡æ¬¾
                    if current_clause_content:
                        clauses.append({
                            "ç« ": clean_string(current_chapter),
                            "èŠ‚": clean_string(current_section),
                            "æ¡æ¬¾ç¼–å·": clean_string(current_clause_number),
                            "æ¡æ¬¾å†…å®¹": clean_string(current_clause_content)
                        })

                    # æå–æ¡æ¬¾ç¼–å·å’Œå†…å®¹
                    clause_match = clause_pattern.match(line.lstrip(' \t\r\n\f\v#-*â€¢Â·'))
                    # ä»æ•è·ç»„ç›´æ¥è·å–ç¼–å·
                    clause_num_part = clause_match.group(1)  # ç¼–å·éƒ¨åˆ†
                    current_clause_number = f"ç¬¬{clause_num_part}æ¡"  # é‡æ„å®Œæ•´ç¼–å·
                    current_clause_content = clause_match.group(2).strip()  # å†…å®¹éƒ¨åˆ†
                    continue

                # å¦‚æœå½“å‰æ­£åœ¨æ”¶é›†æ¡æ¬¾å†…å®¹ï¼Œåˆ™æ·»åŠ åˆ°å½“å‰æ¡æ¬¾å†…å®¹
                if current_clause_content:
                    if current_clause_content:  # å¦‚æœå·²æœ‰å†…å®¹ï¼Œåœ¨å‰é¢åŠ ä¸Šæ¢è¡Œç¬¦
                        current_clause_content += '\n' + line
                    else:  # å¦‚æœè¿˜æ²¡æœ‰å†…å®¹ï¼Œç›´æ¥èµ‹å€¼
                        current_clause_content = line
            # å¤„ç†æœ€åä¸€ä¸ªæ¡æ¬¾ï¼ˆå¦‚æœæœ‰ï¼‰
            if current_clause_content:
                clauses.append({
                    "ç« ": clean_string(current_chapter),
                    "èŠ‚": clean_string(current_section),
                    "æ¡æ¬¾ç¼–å·": clean_string(current_clause_number),
                    "æ¡æ¬¾å†…å®¹": clean_string(current_clause_content)
                })

            if not clauses:
                logging.error("ğŸ“„âŒï¼šæœªæ‰¾åˆ°æ¡æ¬¾å†…å®¹")
                raise ValueError("æœªæ‰¾åˆ°æ¡æ¬¾å†…å®¹")
            # å°†ç¬¬ä¸€æ¡çš„æ¡æ¬¾å†…å®¹æ‹¼æ¥è‡³file_infoä¸­
            file_info += '\n' + clauses[0]['æ¡æ¬¾å†…å®¹']
            return {
                "file_info": clean_string(file_info),
                "clauses": clauses
            }
        except Exception as e:
            logging.error(f"ğŸ“„âŒï¼šæå–æ–‡ä»¶ä¿¡æ¯æ—¶å‡ºé”™ - {e}")
            raise ValueError(f"æå–æ–‡ä»¶ä¿¡æ¯æ—¶å‡ºé”™ - {e}")

    async def kg_extract_from_file_info(
            self,
            filename: str,
            clause_cache: ClauseCache,
            file_info: str
    ) -> dict:
        """
        æŠ½å–å•ä¸ªæ¡æ¬¾å›¾è°±æ•°æ®
        å›¾è°±æ•°æ®ç»“æ„ï¼š
        {
          "node_id": "",
          "node_name": "",
          "node_type": "",
          "properties": {},
          "æ–‡ä»¶ä¾æ®":[node]
        }
        :param filename: æ–‡ä»¶å
        :param clause_cache: æ¡æ¬¾ç¼“å­˜
        :param file_info: æ–‡ä»¶ä¿¡æ¯
        :return:
        """
        try:
            file_info_result = {
                "node_id": "",
                "node_name": "",
                "node_type": "",
                "properties": {},
                "æ³•è§„ä¾æ®": []
            }
            # æŠ½å–å‚æ•°
            extract_prompt = prompt_for_file_info
            extract_schema = schema_for_file_info
            extract_examples = example_for_file_info
            extract_content = f"{filename} æ–‡ä»¶æè¿°ï¼š\n{file_info}"

            extract_result = await self.extractor.entity_and_relationship_extract(
                user_prompt=extract_prompt,
                schema=extract_schema,
                input_text=extract_content,
                examples=extract_examples,
            )
            entities = extract_result.get("entities", [])
            # å¤šä½™æ³•è§„æ–‡ä»¶æ ‡å¿—ï¼Œä¸€ä¸ªæ³•è§„æ–‡ä»¶ä¿¡æ¯ä¸­åªèƒ½æœ‰ä¸€ä¸ªæ³•è§„æ–‡ä»¶ï¼Œå¤„ç†ä¸€ä¸ªæ³•è§„æ–‡ä»¶åç½®æ ‡å¿—ä¸ºçœŸ
            file_info_processed = False
            for entity in entities:
                if not isinstance(entity, Entity):
                    logging.error(f"ğŸ“„âŒï¼šå®ä½“ç±»å‹é”™è¯¯ - {entity}")

                # ä¿å­˜æ–‡ä»¶ä¿¡æ¯
                entity_type = clean_string_with_only_words(entity.entity_type)
                if entity_type == "æ³•è§„æ–‡ä»¶":
                    if file_info_processed:
                        logging.warning("ğŸ“„è­¦å‘Šï¼šä¸€ä¸ªæ³•è§„æ–‡ä»¶ä¿¡æ¯ä¸­åªèƒ½æœ‰ä¸€ä¸ªæ³•è§„æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥é—®é¢˜")
                        continue
                    node_name = entity.name
                    if not node_name:
                        logging.warning("ğŸ“„è­¦å‘Šï¼šæ³•è§„æ–‡ä»¶åç§°ä¸ºç©º")
                        continue
                    node_id = clean_string_for_neo4j_extended(f"{entity_type}_{generate_hex_uuid()}")
                    file_info_result["node_id"] = node_id
                    file_info_result["node_name"] = node_name
                    file_info_result["node_type"] = entity_type
                    file_info_result["properties"] = entity.properties
                    file_info_processed = True
                elif entity_type == "æ³•è§„ä¾æ®":
                    node_name = entity.name
                    if not node_name:
                        logging.warning("ğŸ“„è­¦å‘Šï¼šæ³•è§„ä¾æ®åç§°ä¸ºç©º")
                        continue
                    node_id = clean_string_for_neo4j_extended(f"{entity_type}_{generate_hex_uuid()}")
                    file_info_result["æ³•è§„ä¾æ®"].append({
                        "node_id": node_id,
                        "node_name": node_name,
                        "node_type": entity_type,
                        "properties": entity.properties
                    })
                else:
                    logging.warning(f"ğŸ“„è­¦å‘Šï¼šæœªçŸ¥å®ä½“ç±»å‹ - {entity}")
            clause_cache.file_info = file_info_result
            return file_info_result
        except Exception as e:
            logging.error(f"ğŸ“„âŒï¼šæŠ½å–æ–‡ä»¶ä¿¡æ¯æ—¶å‡ºé”™ - {e}")
            raise ValueError(f"æŠ½å–æ–‡ä»¶ä¿¡æ¯æ—¶å‡ºé”™ - {e}")

    async def kg_extract_from_clause(
            self,
            filename: str,
            clause_cache: ClauseCache,
            one_clause: dict
    ) -> dict:
        """
        æŠ½å–å•ä¸ªæ¡æ¬¾å›¾è°±æ•°æ®
        å›¾è°±æ•°æ®ç»“æ„ï¼š
        {
            "node_id": "",
            "node_name": "",
            "node_type": "",
            "properties": {
                "ç« ": "current_chapter",
                "èŠ‚": "current_section",
                "æ¡": "current_clause_number",
                "æ³•æ¡å…¨æ–‡": "current_clause_content",
                ...
            },
            "æ¡æ¬¾å•å…ƒ": [
                {
                    "node_id": "",
                    "node_name": "",
                    "node_type": "",
                    "properties": {},
                    "å¤–éƒ¨å¼•ç”¨ä¾æ®": [],
                    "å†…éƒ¨å¼•ç”¨ä¾æ®": []
                }
            ]
            ...
        }
        :param filename: æ–‡ä»¶å
        :param one_clause:å•ä¸ªæ¡æ¬¾æ•°æ®
        :param clause_cache:
        :return:
        """
        async with self.semaphore:
            try:
                clause_result = {
                    "node_id": "",
                    "node_name": "",
                    "node_type": "",
                    "properties": {},
                    "æ¡æ¬¾å•å…ƒ": []
                }

                # è·å–æ¡æ¬¾ä¿¡æ¯
                chapter = one_clause.get("ç« ", "")
                section = one_clause.get("èŠ‚", "")
                clause_number = one_clause.get("æ¡æ¬¾ç¼–å·", "")
                clause_content = one_clause.get("æ¡æ¬¾å†…å®¹", "")
                if not clause_number:
                    logging.error(f"ğŸ“„âŒï¼šæ¡æ¬¾ç¼–å·ä¸ºç©º:{one_clause}")
                    raise ValueError("æ¡æ¬¾ç¼–å·ä¸ºç©º")
                # æŠ½å–å‚æ•°
                extract_prompt = prompt_for_clause
                extract_schema = schema_for_clause
                extract_examples = example_for_clause
                extract_content = f"{filename} "
                if chapter:
                    extract_content += f"{chapter} "
                if section:
                    extract_content += f"{section} "
                extract_content += f"{clause_number}ï¼š\n{clause_content}"
                # æŠ½å–æ¡æ¬¾å†…å®¹ä¸­çš„å®ä½“
                """
                {
                    "entities": list[Entity],
                    "relations": list[Relationship],
                    "texts_classes": list[TextClass]
                }
                """
                extract_result = await self.extractor.entity_and_relationship_extract(
                    user_prompt=extract_prompt,
                    schema=extract_schema,
                    input_text=extract_content,
                    examples=extract_examples,
                )
                # ä¸´æ—¶ä¿å­˜æ¡æ¬¾å•å…ƒå’Œå¼•ç”¨ä¾æ®
                clause_units = {}
                references = {}
                processed_keys = []
                # è·å–å®ä½“å’Œå…³ç³»
                entities = extract_result.get("entities", [])
                relations = extract_result.get("relations", [])
                # å¤„ç†å®ä½“
                clause_processed = False
                for entity in entities:
                    if not isinstance(entity, Entity):
                        logging.error(f"ğŸ“„âŒï¼šå®ä½“ç±»å‹é”™è¯¯ - {entity}")
                        continue
                    entity_type = clean_string_with_only_words(entity.entity_type)
                    if entity_type == "æ³•æ¡":
                        if clause_processed:
                            logging.warning("ğŸ“„è­¦å‘Šï¼šä¸€ä¸ªæ³•æ¡ä¸­åªèƒ½æœ‰ä¸€ä¸ªæ³•æ¡ï¼Œè¯·æ£€æŸ¥é—®é¢˜")
                            continue
                        node_name = entity.name
                        if not node_name:
                            logging.warning("ğŸ“„è­¦å‘Šï¼šæ³•æ¡åç§°ä¸ºç©º")
                            continue
                        node_id = clean_string_for_neo4j_extended(f"{entity_type}_{generate_hex_uuid()}")
                        clause_result["node_id"] = node_id
                        clause_result["node_name"] = clause_number
                        clause_result["node_type"] = "æ³•æ¡"
                        clause_result["properties"] = entity.properties
                        clause_result["properties"]["ç« "] = chapter
                        clause_result["properties"]["èŠ‚"] = section
                        clause_result["properties"]["æ¡"] = clause_number
                        clause_result["properties"]["æ³•æ¡å…¨æ–‡"] = clause_content
                        clause_processed = True
                    elif entity_type == "æ¡æ¬¾å•å…ƒ":
                        node_name = entity.name
                        if not node_name:
                            logging.warning("ğŸ“„è­¦å‘Šï¼šæ¡æ¬¾å•å…ƒåç§°ä¸ºç©º")
                            continue
                        node_id = clean_string_for_neo4j_extended(f"{entity_type}_{generate_hex_uuid()}")
                        clause_key = f"{entity_type}_{node_name}"
                        clause_units[clause_key] = {
                            "node_id": node_id,
                            "node_name": node_name,
                            "node_type": "æ¡æ¬¾å•å…ƒ",
                            "properties": entity.properties,
                            "å¤–éƒ¨å¼•ç”¨ä¾æ®": [],
                            "å†…éƒ¨å¼•ç”¨ä¾æ®": []
                        }
                    elif entity_type == "å¼•ç”¨ä¾æ®":
                        node_name = entity.name
                        if not node_name:
                            logging.warning("ğŸ“„è­¦å‘Šï¼šå¼•ç”¨ä¾æ®åç§°ä¸ºç©º")
                            continue
                        node_id = clean_string_for_neo4j_extended(f"{entity_type}_{generate_hex_uuid()}")
                        reference_key = f"{entity_type}_{node_name}"
                        references[reference_key] = {
                            "node_id": node_id,
                            "node_name": node_name,
                            "node_type": "å¼•ç”¨ä¾æ®",
                            "properties": entity.properties
                        }
                    else:
                        logging.error(f"ğŸ“„âŒï¼šæœªçŸ¥å®ä½“ç±»å‹ - {entity}")
                # å¤„ç†å…³ç³»
                for relation in relations:
                    try:
                        if not isinstance(relation, Relationship):
                            logging.error(f"ğŸ“„âŒï¼šå…³ç³»ç±»å‹é”™è¯¯ - {relation}")
                            continue
                        source_key = relation.source
                        target_key = relation.target
                        relation_type = clean_string_with_only_words(relation.type)
                        if not source_key or not target_key or not relation_type:
                            logging.warning("ğŸ“„è­¦å‘Šï¼šå…³ç³»çš„æºèŠ‚ç‚¹æˆ–ç›®æ ‡èŠ‚ç‚¹ä¸ºç©º")
                            continue
                        if relation_type == "å¼•ç”¨":
                            # è·å–æ¡æ¬¾å•å…ƒ
                            source_entity = clause_units.get(source_key)
                            if not source_entity:
                                logging.warning(f"ğŸ“„è­¦å‘Šï¼šå¼•ç”¨å…³ç³»çš„æºèŠ‚ç‚¹ä¸å­˜åœ¨{relation}")
                                # TODO å¯åŠ¨æ¨¡ç³ŠåŒ¹é…
                                continue
                            # è·å–å¼•ç”¨ä¾æ®
                            target_entity = references.get(target_key)
                            if not target_entity:
                                logging.warning(f"ğŸ“„è­¦å‘Šï¼šå¼•ç”¨å…³ç³»çš„ç›®æ ‡èŠ‚ç‚¹ä¸å­˜åœ¨{relation}")
                                # TODO å¯åŠ¨æ¨¡ç³ŠåŒ¹é…
                                continue
                            # è·å–å¼•ç”¨ä¾æ®æ˜¯å¦æ˜¯å†…éƒ¨æ¡æ¬¾
                            inner_tag = clean_string_with_only_words(target_entity.get("properties", {}).get("æ˜¯å¦æœ¬æ–‡ä»¶å†…å¼•ç”¨", "å¦"))
                            if inner_tag == "æ˜¯":
                                source_entity["å†…éƒ¨å¼•ç”¨ä¾æ®"].append(target_entity)
                            else:
                                source_entity["å¤–éƒ¨å¼•ç”¨ä¾æ®"].append(target_entity)
                            processed_keys.append(target_key)
                    except Exception as e:
                        logging.error(f"ğŸ“„âŒï¼šå¤„ç†å…³ç³»{relation}æ—¶å‡ºé”™ - {e}")
                        continue
                # æ£€éªŒæœªè¢«ä½¿ç”¨çš„å¼•ç”¨ä¾æ®
                for key, _ in references.items():
                    if key not in processed_keys:
                        logging.warning(f"ğŸ“„è­¦å‘Šï¼šå¼•ç”¨ä¾æ®{key}æœªè¢«ä½¿ç”¨ï¼")
                # å°†æ¡æ¬¾å•å…ƒæ·»åŠ åˆ°ç»“æœä¸­
                for entity in clause_units.values():
                    clause_result["æ¡æ¬¾å•å…ƒ"].append(entity)
                clause_cache.clause_cache[clause_number] = clause_result
                return clause_result
            except Exception as e:
                logging.error(f"ğŸ“„âŒï¼šå¤„ç†æ–‡ä»¶{filename}æ—¶å‡ºé”™ - {e}")

    @staticmethod
    async def process_extracted_data(
            filename: str,
            extracted_file_info: dict,
            extracted_success_clauses: list[dict],
            extracted_failed_clauses: list[dict]
    ) -> dict:
        """
        å¤„ç†æå–çš„æ³•è§„æ–‡ä»¶ä¿¡æ¯

        :param filename:
        :param extracted_file_info:
        :param extracted_success_clauses:
        :param extracted_failed_clauses:
        :return:
        """
        try:
            final_kg = {
                "nodes": [],
                "edges": []
            }
            # å°†æ³•è§„æ–‡ä»¶å’Œæ–‡ä»¶ä¾æ®èŠ‚ç‚¹å’Œå…³ç³»åŠ å…¥
            file_node_id = extracted_file_info.get("node_id")
            file_node_name = extracted_file_info.get("node_name")
            file_node_type = extracted_file_info.get("node_type")
            if not file_node_id or not file_node_name or not file_node_type:
                logging.error(f"ğŸ“„ğŸ”¥ï¼šæ³•è§„æ–‡ä»¶ä¿¡æ¯ä¸å®Œæ•´{extracted_file_info}")
                raise ValueError("æ³•è§„æ–‡ä»¶ä¿¡æ¯ä¸å®Œæ•´")
            final_kg["nodes"].append(
                {
                    "node_id": file_node_id,
                    "node_name": file_node_name,
                    "node_type": file_node_type,
                    "properties": extracted_file_info.get("properties", {}),
                    "filename": filename
                }
            )
            # å¤„ç†æ³•è§„ä¾æ®
            file_basis = extracted_file_info.get("æ³•è§„ä¾æ®", [])
            for basis in file_basis:
                basis_node_id = basis.get("node_id")
                basis_node_name = basis.get("node_name")
                basis_node_type = basis.get("node_type")
                if not basis_node_id or not basis_node_name or not basis_node_type:
                    logging.warning(f"ğŸ“„ğŸ”§ï¼šæ³•è§„ä¾æ®ä¿¡æ¯ä¸å®Œæ•´{basis}")
                    continue
                final_kg["nodes"].append(
                    {
                        "node_id": basis_node_id,
                        "node_name": basis_node_name,
                        "node_type": basis_node_type,
                        "properties": basis.get("properties", {}),
                        "filename": filename
                    }
                )
                final_kg["edges"].append(
                    {
                        "source_id": file_node_id,
                        "target_id": basis_node_id,
                        "relation_type": "ä¾æ®",
                        "directionality": "å•å‘",
                        "properties": {},
                        "filename": filename
                    }
                )

            # å°†extracted_failed_clausesä¸­çš„æ³•æ¡èŠ‚ç‚¹å’Œå…³ç³»åŠ å…¥
            for clause in extracted_failed_clauses:
                clause_number = clause.get("æ¡æ¬¾ç¼–å·")
                clause_text = clause.get("æ¡æ¬¾å†…å®¹")
                if not clause_number or not clause_text:
                    logging.warning(f"ğŸ“„ğŸ”§ï¼šæ³•æ¡ä¿¡æ¯ä¸å®Œæ•´{clause}")
                    continue
                clause_node_id = clean_string_for_neo4j_extended(f"æ³•æ¡_{generate_hex_uuid()}")
                clause_node_name = clause_number
                clause_node_type = "æ³•æ¡"
                clause_properties = {
                    "ç« ": clause.get("ç« "),
                    "èŠ‚": clause.get("èŠ‚"),
                    "æ¡": clause_number,
                    "æ³•æ¡å…¨æ–‡": clause_text
                }
                final_kg["nodes"].append(
                    {
                        "node_id": clause_node_id,
                        "node_name": clause_node_name,
                        "node_type": clause_node_type,
                        "properties": clause_properties,
                        "filename": filename
                    }
                )
                final_kg["edges"].append(
                    {
                        "source_id": file_node_id,
                        "target_id": clause_node_id,
                        "relation_type": "åŒ…å«",
                        "directionality": "å•å‘",
                        "properties": {},
                        "filename": filename
                    }
                )

            # å¼•ç”¨ä¾æ®æ˜ å°„
            inner_reference_mapping = {}
            outer_reference_mapping = {}
            inner_reference_id_mapping = {}
            outer_reference_id_mapping = {}
            # æ¡æ¬¾å•å…ƒåˆ°æ³•æ¡çš„æ˜ å°„
            unit_to_clause_mapping = {}
            # å°†extracted_success_clausesä¸­çš„æ³•æ¡ã€æ¡æ¬¾å•å…ƒã€å¼•ç”¨ä¾æ®èŠ‚ç‚¹å’Œå…³ç³»åŠ å…¥
            for clause in extracted_success_clauses:
                clause_node_id = clause.get("node_id")
                clause_node_name = clause.get("node_name")
                clause_node_type = clause.get("node_type")
                if not clause_node_id or not clause_node_name or not clause_node_type:
                    logging.warning(f"ğŸ“„ğŸ”§ï¼šæ³•æ¡ä¿¡æ¯ä¸å®Œæ•´{clause}")
                    continue
                # æ·»åŠ æ³•æ¡èŠ‚ç‚¹å’Œå…³ç³»
                final_kg["nodes"].append(
                    {
                        "node_id": clause_node_id,
                        "node_name": clause_node_name,
                        "node_type": clause_node_type,
                        "properties": clause.get("properties", {}),
                        "filename": filename
                    }
                )
                final_kg["edges"].append(
                    {
                        "source_id": file_node_id,
                        "target_id": clause_node_id,
                        "relation_type": "åŒ…å«",
                        "directionality": "å•å‘",
                        "properties": {},
                        "filename": filename
                    }
                )
                # å°†æ³•æ¡ä½œä¸ºå†…éƒ¨å¼•ç”¨ä¾æ®ä¹‹ä¸€
                try:
                    clause_article = clean_string_with_only_words(clause.get("properties", {}).get("æ¡"))
                except Exception:
                    clause_article = ""
                if not clause_article:
                    logging.warning(f"ğŸ“„ğŸ”§ï¼šæ³•æ¡ä¿¡æ¯ç¼ºå°‘æ¡ç¼–å·{clause}")
                else:
                    inner_reference_id_mapping[clause_article] = clause_node_id
                # å¤„ç†æ¡æ¬¾å•å…ƒèŠ‚ç‚¹å’Œå…³ç³»
                clause_units = clause.get("æ¡æ¬¾å•å…ƒ", [])
                for unit in clause_units:
                    unit_node_id = unit.get("node_id")
                    unit_node_name = unit.get("node_name")
                    unit_node_type = unit.get("node_type")
                    if not unit_node_id or not unit_node_name or not unit_node_type:
                        logging.warning(f"ğŸ“„ğŸ”§ï¼šæ¡æ¬¾å•å…ƒä¿¡æ¯ä¸å®Œæ•´{unit}")
                        continue
                    final_kg["nodes"].append(
                        {
                            "node_id": unit_node_id,
                            "node_name": unit_node_name,
                            "node_type": unit_node_type,
                            "properties": unit.get("properties", {}),
                            "filename": filename
                        }
                    )
                    final_kg["edges"].append(
                        {
                            "source_id": clause_node_id,
                            "target_id": unit_node_id,
                            "relation_type": "åŒ…å«",
                            "directionality": "å•å‘",
                            "properties": {},
                            "filename": filename
                        }
                    )
                    # å°†æ¡æ¬¾å•å…ƒåˆ°æ³•æ¡çš„æ˜ å°„åŠ å…¥
                    unit_to_clause_mapping[unit_node_id] = clause_node_id
                    # å°†æ¡æ¬¾å•å…ƒä½œä¸ºå†…éƒ¨å¼•ç”¨ä¾æ®ä¹‹ä¸€
                    try:
                        unit_article = clean_string_with_only_words(unit.get("properties", {}).get("å•å…ƒç¼–å·"))
                    except Exception:
                        unit_article = ""
                    if not unit_article:
                        logging.warning(f"ğŸ“„ğŸ”§ï¼šæ¡æ¬¾å•å…ƒä¿¡æ¯ç¼ºå°‘å•å…ƒç¼–å·{unit}")
                    else:
                        inner_reference_id_mapping[unit_article] = unit_node_id
                    # æ·»åŠ å†…éƒ¨å¼•ç”¨ä¾æ®å’Œå¤–éƒ¨å¼•ç”¨ä¾æ®
                    inner_reference = unit.get("å†…éƒ¨å¼•ç”¨ä¾æ®", [])
                    for ref in inner_reference:
                        inner_reference_mapping[unit_node_id] = ref
                    outer_reference = unit.get("å¤–éƒ¨å¼•ç”¨ä¾æ®", [])
                    for ref in outer_reference:
                        outer_reference_mapping[unit_node_id] = ref

            # å¤„ç†å†…éƒ¨å¼•ç”¨ä¾æ®
            for unit_node_id, inner_ref in inner_reference_mapping.items():
                ref_node_id = inner_ref.get("node_id")
                ref_node_name = inner_ref.get("node_name")
                ref_node_type = inner_ref.get("node_type")
                if not ref_node_id or not ref_node_name or not ref_node_type:
                    logging.warning(f"ğŸ“„ğŸ”§ï¼šå¼•ç”¨ä¾æ®ä¿¡æ¯ä¸å®Œæ•´{inner_ref}")
                    continue
                # åŒ¹é…å†…éƒ¨æ¡æ¬¾å•å…ƒ
                try:
                    inner_ref_article = clean_string_with_only_words(inner_ref.get("properties", {}).get("æ¡æ¬¾ç¼–å·"))
                except Exception:
                    inner_ref_article = ""
                if not inner_ref_article:
                    logging.warning(f"ğŸ“„ğŸ”§ï¼šå¼•ç”¨ä¾æ®ä¿¡æ¯ç¼ºå°‘æ¬¾é¡¹ç¼–å·{inner_ref}")
                else:
                    ref_unit_node_id = inner_reference_id_mapping.get(inner_ref_article)
                    if not ref_unit_node_id:
                        logging.warning(f"ğŸ“„ğŸ”§ï¼šå¼•ç”¨ä¾æ®æ¬¾é¡¹ç¼–å·æœªæ‰¾åˆ°å¯¹åº”æœ¬æ–‡ä»¶æ¡æ¬¾å•å…ƒ{inner_ref}")
                        # TODOï¼šåŠ å…¥æ¨¡ç³ŠåŒ¹é…
                        # å¦‚æœæ˜¯â€œç¬¬Xæ¡ç¬¬Xé¡¹â€ï¼Œåˆ™å°è¯•åŒ¹é…â€œç¬¬Xæ¡ç¬¬ä¸€æ¬¾ç¬¬Xé¡¹â€
                        match = re.match(
                            r'^(ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+æ¡)(ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+é¡¹)$',
                            inner_ref_article)
                        if match:
                            article_part, item_part = match.groups()
                            # å°è¯•"ç¬¬Xæ¡ç¬¬ä¸€æ¬¾ç¬¬Xé¡¹"æ ¼å¼
                            alternative_article = f"{article_part}ç¬¬ä¸€æ¬¾{item_part}"
                            logging.warning(f"ğŸ“„ğŸ”§ï¼šå°è¯•åŒ¹é…{alternative_article}")
                            ref_unit_node_id = inner_reference_id_mapping.get(alternative_article)
                        if not ref_unit_node_id:
                            # å°è¯•åŒ¹é…â€œç¬¬Xæ¡ç¬¬Xæ¬¾â€
                            match = re.match(r'^(ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+æ¡)(ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+æ¬¾)$',
                                             inner_ref_article)
                            if match:
                                article_part, clause_part = match.groups()
                                alternative_article = f"{article_part}{clause_part}"
                                logging.warning(f"ğŸ“„ğŸ”§ï¼šå°è¯•åŒ¹é…{alternative_article}")
                                ref_unit_node_id = inner_reference_id_mapping.get(alternative_article)
                            if not ref_unit_node_id:
                                # å¦‚æœå«â€œç¬¬Xæ¡â€ï¼Œåˆ™å°è¯•åŒ¹é…â€œç¬¬Xæ¡â€
                                match = re.match(r'(ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+æ¡)', inner_ref_article)
                                if match:
                                    basic_article = match.group(1)
                                    logging.warning(f"ğŸ“„ğŸ”§ï¼šå°è¯•åŒ¹é…{basic_article}")
                                    ref_unit_node_id = inner_reference_id_mapping.get(basic_article)
                    if not ref_unit_node_id:
                        logging.warning(f"ğŸ“„ğŸ”§ï¼šæ¨¡ç³ŠåŒ¹é…åå¼•ç”¨ä¾æ®æ¬¾é¡¹ç¼–å·æœªæ‰¾åˆ°å¯¹åº”æœ¬æ–‡ä»¶æ¡æ¬¾å•å…ƒ{inner_ref}")
                    if ref_unit_node_id == unit_node_id:
                        logging.warning(f"ğŸ“„ğŸ”§ï¼šå¼•ç”¨ä¾æ®æ¬¾é¡¹ç¼–å·ä¸å½“å‰æ¡æ¬¾å•å…ƒç¼–å·ä¸€è‡´{inner_ref}")
                    elif ref_unit_node_id == unit_to_clause_mapping.get(unit_node_id):
                        logging.warning(f"ğŸ“„ğŸ”§ï¼šå¼•ç”¨ä¾æ®æ¬¾é¡¹ç¼–å·ä¸å½“å‰æ¡æ¬¾å•å…ƒå¯¹åº”çš„æ³•æ¡ç¼–å·ä¸€è‡´{inner_ref}")
                    else:
                        final_kg["edges"].append(
                            {
                                "source_id": unit_node_id,
                                "target_id": ref_unit_node_id,
                                "relation_type": "ä¾æ®",
                                "directionality": "å•å‘",
                                "properties": {},
                                "filename": filename
                            }
                        )

            # å¤„ç†å¤–éƒ¨å¼•ç”¨ä¾æ®
            for unit_node_id, outer_ref in outer_reference_mapping.items():
                ref_node_id = outer_ref.get("node_id")
                ref_node_name = outer_ref.get("node_name")
                ref_node_type = outer_ref.get("node_type")
                if not ref_node_id or not ref_node_name or not ref_node_type:
                    logging.warning(f"ğŸ“„ğŸ”§ï¼šå¼•ç”¨ä¾æ®ä¿¡æ¯ä¸å®Œæ•´{outer_ref}")
                    continue
                # å¦‚æœå¤–éƒ¨å¼•ç”¨ä¾æ®èŠ‚ç‚¹idæ˜ å°„ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºèŠ‚ç‚¹å¹¶å»ºç«‹å…³ç³»
                ref_unit_node_id = outer_reference_id_mapping.get(clean_string_with_only_words(ref_node_name))
                # TODO:å¤„ç†åŒä¹‰å®ä½“
                if not ref_unit_node_id:
                    final_kg["nodes"].append(
                        {
                            "node_id": ref_node_id,
                            "node_name": ref_node_name,
                            "node_type": ref_node_type,
                            "properties": outer_ref.get("properties", {}),
                            "filename": filename
                        }
                    )
                    final_kg["edges"].append(
                        {
                            "source_id": unit_node_id,
                            "target_id": ref_node_id,
                            "relation_type": "æ¶‰åŠ",
                            "directionality": "å•å‘",
                            "properties": {},
                            "filename": filename
                        }
                    )
                    outer_reference_id_mapping[clean_string_with_only_words(ref_node_name)] = ref_unit_node_id
                elif ref_unit_node_id == unit_node_id:
                    logging.warning(f"ğŸ“„ğŸ”§ï¼šå¼•ç”¨ä¾æ®æ¬¾é¡¹ç¼–å·ä¸å½“å‰æ¡æ¬¾å•å…ƒç¼–å·ä¸€è‡´{outer_ref}")
                # å¦‚æœå¤–éƒ¨å¼•ç”¨ä¾æ®èŠ‚ç‚¹idæ˜ å°„å­˜åœ¨ï¼Œåˆ™ç›´æ¥åˆ›å»ºå…³ç³»
                else:
                    final_kg["edges"].append(
                        {
                            "source_id": unit_node_id,
                            "target_id": ref_unit_node_id,
                            "relation_type": "æ¶‰åŠ",
                            "directionality": "å•å‘",
                            "properties": {},
                            "filename": filename
                        }
                    )
            return final_kg
        except Exception as e:
            logging.error(f"ğŸ“„ğŸ”§ï¼šå¤„ç†æŠ½å–æ•°æ®æ—¶å‡ºé”™{e}")
            raise e

    @staticmethod
    async def _save_cache_to_json(
            cache_data: ClauseCache,
            output_dir,
            filename
    ):
        """
        å°†æ¡æ¬¾æ•°æ®ä¿å­˜ä¸ºJSONæ ¼å¼
        :param cache_data: å­—å…¸æ•°æ®
        :param output_dir: è¾“å‡ºç›®å½•è·¯å¾„
        :param filename: æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        """
        # TODO
        pass

    @staticmethod
    async def _load_cache_from_json(
            filepath
    ):
        """
        ä»JSONæ–‡ä»¶ä¸­åŠ è½½æ¡æ¬¾æ•°æ®ï¼Œå¹¶æ•´ç†æˆdict
        :param filepath: æ–‡ä»¶è·¯å¾„
        :return: æ¡æ¬¾æ•°æ®ï¼ˆå­—å…¸æˆ–åˆ—è¡¨ï¼‰
        """
        # TODO
        pass


def clean_string(text: str) -> str:
    # æ›¿æ¢å…¨è§’ç©ºæ ¼
    cleaned = replace_full_corner_space(text)
    # æ›¿æ¢é›¶å®½å­—ç¬¦
    cleaned = replace_zero_width_chars(cleaned)
    # å°†è¿ç»­çš„æ¢è¡Œç¬¦æ›¿æ¢ä¸ºå•ä¸ªæ¢è¡Œç¬¦
    cleaned = re.sub(r'\n+', '\n', cleaned)
    # ç§»é™¤è¡Œé¦–è¡Œå°¾çš„ç©ºç™½å­—ç¬¦
    cleaned = re.sub(r'^[ \t]+|[ \t]+$', '', cleaned, flags=re.MULTILINE)
    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    cleaned = re.sub(r'\s+', ' ', cleaned).strip()
    return cleaned


if __name__ == "__main__":
    # è¯»å–ç¤ºä¾‹æ–‡ä»¶
    file_path = r"F:\ä¼ä¸šå¤§è„‘çŸ¥è¯†åº“ç³»ç»Ÿ\8.1é¡¹ç›®\æ•°æ®å¤„ç†\æ¸…æ´—çš„æ•°æ®\å›½å®¶è§„ç« åº“\å®‰å…¨ç”Ÿäº§\ç”Ÿäº§å®‰å…¨äº‹æ•…åº”æ€¥é¢„æ¡ˆç®¡ç†åŠæ³•.txt"
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except FileNotFoundError:
        # å¦‚æœçœŸå®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„ç¤ºä¾‹å†…å®¹è¿›è¡Œæµ‹è¯•
        raise ValueError("æ–‡ä»¶ä¸å­˜åœ¨")

    extractor = ClauseExtractor()
    result = asyncio.run(
        extractor.split_clause(
            text=content
        )
    )

    # æ‰“å°ç»“æœ
    print("æ–‡ä»¶ä¿¡æ¯:", result["file_info"])
    print("\næ¡æ¬¾æ•°é‡:", len(result["clauses"]))
    print("\næ¡æ¬¾ç¤ºä¾‹:")
    for i, clause in enumerate(result["clauses"]):
        print(f"\næ¡æ¬¾ {i + 1}: ")
        print(f"  ç« : {clause['ç« ']}")
        print(f"  èŠ‚: {clause['èŠ‚']}")
        print(f"  æ¡æ¬¾ç¼–å·: {clause['æ¡æ¬¾ç¼–å·']}")
        print(f"  æ¡æ¬¾å†…å®¹: {clause['æ¡æ¬¾å†…å®¹']}")

# 1. ç»Ÿè®¡æŠ½å–å‡ºæ¥çš„æ¡æ¬¾æ•°å’Œæœ€åä¸€é¡¹æ¡æ¬¾çš„ç¼–å·æ˜¯å¯¹åº”ä¸Šçš„
