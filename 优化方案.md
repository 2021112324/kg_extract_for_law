# 实体关系抽取阶段设计
## 优先级
高
## 动机
### 1. one-shot vs multi-shot
1. one-shot: 一次性抽取实体和关系
（1）优势:
- 工程实现简单：单次调用、无中间态管理
- 速度与成本较低：Token 消耗少、抽取速度快 
- 对结构简单的文本友好
（2）劣势:
- 抽取稳定性差：实体存在但关系缺失、关系存在但主体/客体错配、关系跨句错误连接
2. multi-shot: 先抽实体，然后将实体作为提示词的一部分，抽取关系，该方式
（1）优势:
- 实体边界更清晰，关系更准确：大幅减少关系幻觉、主客体错位
- 更强的 Schema 约束能力
（2）劣势:
- Token 与成本更高：少两次 LLM 调用、实体列表可能过长导致抽取失败
- 错误可能级联：第一步漏抽实体、第二步永远不可能补救

## 方案
### 长文本采取one-shot、短文本采取multi-shot
目前采取的初步方案

### 多轮对话继承
示例
- Q1：抽实体
- A1：实体列表
- Q2：基于刚才的实体抽关系

理论可行，但工程上风险最高
问题点:
1. 上下文不可控
- 模型可能遗忘、重写、自行修正上一轮结果
2. 不利于批处理与并发 
- 对话态 = 强状态依赖
- 很难 scale

该方案待调研

### multi-shot:分块抽取 + 局部上下文实体注入 + 延迟关系补全
#### Step 1：并行实体抽取（无等待）
对每个 chunk：
- 独立抽取实体
- 记录：
  - 实体类型
  - 标准名
  - 别名
  - 出现 chunk_id
这一步 完全并行，不存在 “长时间等待”。
#### Step 2：实体合并（全局，但轻量）
合并内容仅包括：
- 实体 ID
- 实体类型
- 规范名称
- 出现位置列表（chunk_id list）
不做关系、不做属性扩展。
这是一个轻量级索引构建阶段
#### Step 3：关系抽取 —— 核心改造点
1. 局部实体子集注入（不是全集）
对每个 chunk，构造 entity window：
```text
实体子集 =
- 本 chunk 出现的实体
+ 相邻 chunk（±1）出现的实体
+ 全文高频 / 核心实体（如“本法”“该条例”）
```
实体列表规模直接从 O(N) 降到 O(k)，k ≪ N
2. 关系抽取分两类
A. 块内 / 邻接块关系（主流程，95%）
- 在 chunk i
- 使用 entity window
- 抽取关系
- 并行执行
B. 延迟跨块关系（补偿流程）
单独处理，不阻塞主流程。

#### Step 4：跨块关系补全（延迟执行）
不需要在主流程解决跨块关系。
典型做法：
- 识别“未闭合实体”：
  - 实体只出现一次、关系少于阈值
  - 对这些实体：拉取其所有出现的 chunk、组成 mini-context、单独跑一次关系抽取
- 实体关系补全：
  - 以验证而非抽取的策略，使用大模型补全图谱

# 文本分块
## 优先级
中
## 动机
1. 长文本抽取时，需要将长文本切分为多个块，对每个块进行抽取。
2. 块的抽取时间取决于很多因素，如块大小、块数量、块内关系数量、块内实体数量等
3. 以固定大小切分块，不同任务下的抽取时间差异较大

## 方案
### 动态分块
- 第一批分块按照固定大小进行切分
- 获取抽取结果，对抽取结果进行统计
- 根据第一批分块的(抽取结果大小/抽取时长)，动态后续分块大小
### 章节、段落级分块
- 以章节、段落级等分块
- 单个块过长时，按大小切分

# 提示词优化
## 优先级
中
## 动机
1. 格式化 json 本体schema 作为提示词会降低抽取质量
2. 本体schema用于让 LLM 理解本体语义，而自然语言形式的提示词则更利于大模型的理解。
3. 提示词优化应减少不必要的token消耗，而格式化的json内，换行、空格、缩进会增加token消耗。

## 方案
### 压缩json，减少token消耗
格式化json：
将
```dict
{
  "实体": [
    "实体1": {
      ...
    }
  ],
  "关系": [
    "关系1": {
      ...
    }
  ]
}
```
转化为
{"实体": ["实体1": { ... }],"关系": ["关系1": { ... }]}
减少token消耗

### json转markdown
将json转化为markdown形式，例如：
```markdown
# 实体
- 实体1:描述
    - 属性1: 描述
# 关系
- 关系1:描述
    - 关系三元组: A-关系-B
```
优点：减少token消耗、自然语言形式更易于大模型理解任务
隐患：缺少了json结构的强约束力

# 重试机制 
## 优先级
低
## 动机
1. 当前抽取流程存在错误时，会进行一定次数的重试，每次重试间隔时间递增。
2. 当前的重试机制并未对任务本身进行优化，基本避免网络错误导致的重试，可能存在多次抽取结果发生相同错误的情况。
## 方案
### 优化重试机制
待调研

# 图谱合并过滤
## 优先级
高
## 动机
1. 目前的图谱合并策略仅基于type和name进行合并，无法处理同义实体识别合并
## 方案
### 参考优化代码

# 图谱验证
## 优先级
低
## 动机
1. 大模型抽取结果存在错误时，需要验证结果，对错误进行修正。
2. 基于《GPT-NER: Named Entity Recognition via Large Language Models》论文启发，可以将结果交给大模型进行验证，对错误进行修正。
## 方案
### 添加大模型验证阶段

# 图谱节点溯源
## 优先级
高
## 动机
1. 在某些领域的知识图谱中，知识可能需要来源依据
2. Langextract框架能够实现实体溯源，先前由于溯源逻辑未设计+关系的溯源困难，未实现
3. **难点**：Langextract框架的溯源实体对齐在某些领域失败率较高
## 方案
### 原文本作为节点
1. 添加原文本作为节点，赋值id
2. 节点和边添加特殊属性：溯源文本，数据结构为列表，以便后续合并  
3. 溯源文本内每个元素为结构体，包括：原文id、起始位置、结束位置、匹配方式
4. 原文本合并和溯源信息列表合并
5. 保留节点对应文本片段id，记录id频数
**待完善** 暂不考虑关系溯源
### 基于Langextract框架实现溯源
需要处理以下问题：
- 关系溯源
- 节点多来源合并


# 实现
## 图谱节点溯源
### 原文本作为节点
#### 步骤
[x]1. 添加原文本作为节点，赋值id
[x]2. 节点和边添加特殊属性：溯源文本，数据结构为列表，以便后续合并  
[x]3. 溯源文本内每个元素为结构体，包括：原文id、起始位置、结束位置、匹配方式
[x]4. 原文本合并和溯源信息列表合并
[x]5. 保留节点对应文本片段id
[x]6. 建立节点和溯源文本关系，节点定位信息作为边属性
#### 实现位置
- app/infrastructure/information_extraction：2、3
- app/services/ai/kg_extract_service.py: 4
- app/services/core/kg_service.py: 1、5、6

## 图谱抽取优化
### 每个文件要求对应一个图谱抽取的阶段性任务
#### 步骤
[x]1. 每个minio抽取任务都要记录原始文件名
[x]2. 每个minio抽取任务结束后都要在结果中保留原始文件名
[x]3. 策略选择，文件领域DocumentLevel时，每个文件抽取图谱后保存, 并为节点添加文件信息
#### 实现位置
- app/services/core/kg_service.py：1、3
- app/services/ai/kg_extract_service.py：2、3

### 修复隐患：oneshot抽取时，提示词中关系schema在实体schema前，导致抽取结果错误
#### 步骤
[x]重置提示词组合前schema内字段顺序，使其按实体关系先后顺序拼接提示词
#### 实现位置
- F:\企业大脑知识库系统\8.1项目\抽取代码\kg_extract_for_law\app\infrastructure\information_extraction\langextract_adapter.py
- F:\企业大脑知识库系统\8.1项目\抽取代码\kg_extract_for_law\app\infrastructure\information_extraction\method\prompt\prompt.py

### 添加单个文件的进度计算
#### 步骤
[]记录文件大小和每个分块处理的分块大小，通过计算在数据库记录文件处理进度
